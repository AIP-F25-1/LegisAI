{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize Hugging Face summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def chunk_text(text, max_chars=2000):\n",
    "    \"\"\"\n",
    "    Chunk text by max character count (safer for tokenized model input),\n",
    "    keeps paragraphs together.\n",
    "    \"\"\"\n",
    "    paragraphs = text.split('\\n')\n",
    "    chunks = []\n",
    "    current = ''\n",
    "    for para in paragraphs:\n",
    "        if len(current) + len(para) > max_chars and current:\n",
    "            chunks.append(current.strip())\n",
    "            current = ''\n",
    "        current += para + '\\n'\n",
    "    if current:\n",
    "        chunks.append(current.strip())\n",
    "    return chunks\n",
    "\n",
    "def summarize_case(text):\n",
    "    summaries = []\n",
    "    for chunk in chunk_text(text, max_chars=1800):  # Safe margin for BART (max 2000 chars)\n",
    "        try:\n",
    "            summary = summarizer(chunk, max_length=120, min_length=30, do_sample=False)\n",
    "            summaries.append(summary[0]['summary_text'])\n",
    "        except Exception as e:\n",
    "            summaries.append(f\"Error summarizing chunk: {str(e)}\")\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "def summarize_case(text):\n",
    "    summaries = []\n",
    "    for chunk in chunk_text(text):\n",
    "        summary = summarizer(chunk, max_length=120, min_length=30, do_sample=False)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "def extract_headnotes(text):\n",
    "    lines = text.split('\\n')\n",
    "    headnote_text = \"\\n\".join(lines[:4]) if len(lines) >= 4 else text\n",
    "    summaries = []\n",
    "    for chunk in chunk_text(headnote_text, max_chars=1200):  # safe for short headnotes\n",
    "        try:\n",
    "            summary = summarizer(chunk, max_length=60, min_length=20, do_sample=False)\n",
    "            summaries.append(summary[0]['summary_text'])\n",
    "        except Exception as e:\n",
    "            summaries.append(f\"Error summarizing chunk: {str(e)}\")\n",
    "    return \"\\n\".join(summaries)\n",
    "\n",
    "def extract_ratio_obiter(text):\n",
    "    prompt = \"Extract the ratio decidendi (the key legal principle) and any obiter dicta (non-binding remarks) from this case:\\n\"\n",
    "    max_chars = 2000  # 1024 BART tokens â‰ˆ 2000-3000 chars, leave margin for prompt\n",
    "    results = []\n",
    "    paragraphs = text.split('\\n')\n",
    "    chunk = \"\"\n",
    "    for para in paragraphs:\n",
    "        # Always reserve room for the prompt text by counting total length\n",
    "        if len(prompt) + len(chunk) + len(para) > max_chars:\n",
    "            try:\n",
    "                summary = summarizer(prompt + chunk, max_length=130, min_length=30, do_sample=False)\n",
    "                results.append(summary[0]['summary_text'])\n",
    "            except Exception as e:\n",
    "                results.append(f\"Error: {str(e)}\")\n",
    "            chunk = \"\"\n",
    "        chunk += para + \"\\n\"\n",
    "    if chunk:\n",
    "        try:\n",
    "            summary = summarizer(prompt + chunk, max_length=130, min_length=30, do_sample=False)\n",
    "            results.append(summary[0]['summary_text'])\n",
    "        except Exception as e:\n",
    "            results.append(f\"Error: {str(e)}\")\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "def contrastive_summary(text):\n",
    "    pro_plaintiff = \"\"\n",
    "    pro_defendant = \"\"\n",
    "    for para in text.split('\\n\\n'):\n",
    "        lower = para.lower()\n",
    "        if \"plaintiff\" in lower or \"appellant\" in lower:\n",
    "            pro_plaintiff += para + \"\\n\"\n",
    "        elif \"defendant\" in lower or \"appellee\" in lower:\n",
    "            pro_defendant += para + \"\\n\"\n",
    "    summary_plaintiff = summarize_case(pro_plaintiff) if pro_plaintiff else \"No plaintiff/appellant arguments found.\"\n",
    "    summary_defendant = summarize_case(pro_defendant) if pro_defendant else \"No defendant/appellee arguments found.\"\n",
    "    return summary_plaintiff, summary_defendant\n",
    "\n",
    "# --- Multi-Case Loop ---\n",
    "cases_folder = \"D:/AIP/data/\"\n",
    "for filename in os.listdir(cases_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(os.path.join(cases_folder, filename), 'r', encoding='utf-8') as f:\n",
    "            case = json.load(f)\n",
    "        casebody = case.get(\"casebody\", {})\n",
    "        opinions = casebody.get(\"opinions\", [])\n",
    "        case_text = opinions[0].get(\"text\", \"\") if opinions and isinstance(opinions[0], dict) else \"\"\n",
    "        if not case_text or len(case_text) < 20:\n",
    "            continue  # skip empty/invalid cases\n",
    "        print(f\"\\n=== {filename} ===\")\n",
    "        try:\n",
    "            print(\"--- Summary ---\")\n",
    "            print(summarize_case(case_text))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in summary for {filename}: {str(e)}\")\n",
    "        print(\"--- Headnotes ---\")\n",
    "        print(extract_headnotes(case_text))\n",
    "        print(\"--- Ratio Decidendi & Obiter Dicta ---\")\n",
    "        try:\n",
    "            print(extract_ratio_obiter(case_text))\n",
    "        except Exception as e:\n",
    "            print(f\"Error during ratio/obiter extraction: {str(e)}\")\n",
    "        print(\"--- Contrastive Summarization ---\")\n",
    "        plaintiff_summary, defendant_summary = contrastive_summary(case_text)\n",
    "        print(\"Plaintiff/Appellant:\\n\", plaintiff_summary)\n",
    "        print(\"Defendant/Appellee:\\n\", defendant_summary)\n"
   ],
   "id": "e120641927659eb5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
